{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "Chatbot with 1000 q&a data.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZeF9fVLnIxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras import preprocessing , utils\n",
        "import string\n",
        "import tensorflow as tf\n",
        "# NLTK\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_9Q5QU9nIxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  Loading Data\n",
        "import pandas as pd\n",
        "import gzip\n",
        "\n",
        "def parse(path):\n",
        "  g = gzip.open(path, 'rb')\n",
        "  for l in g:\n",
        "    yield eval(l)\n",
        "\n",
        "def getDF(path):\n",
        "  i = 0\n",
        "  df = {}\n",
        "  for d in parse(path):\n",
        "    df[i] = d\n",
        "    i += 1\n",
        "  return pd.DataFrame.from_dict(df, orient='index')\n",
        "\n",
        "df = getDF('qa_Electronics.json.gz')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVgqYqnFnIxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.set_option('display.max_columns',None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tyn2V0sVnIxi",
        "colab_type": "code",
        "colab": {},
        "outputId": "eeeff64f-53f7-4959-c59e-1981dbd0ac8a"
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questionType</th>\n",
              "      <th>asin</th>\n",
              "      <th>answerTime</th>\n",
              "      <th>unixTime</th>\n",
              "      <th>question</th>\n",
              "      <th>answerType</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>yes/no</td>\n",
              "      <td>0594033926</td>\n",
              "      <td>Dec 27, 2013</td>\n",
              "      <td>1.388131e+09</td>\n",
              "      <td>Is this cover the one that fits the old nook c...</td>\n",
              "      <td>Y</td>\n",
              "      <td>Yes this fits both the nook color and the same...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>yes/no</td>\n",
              "      <td>0594033926</td>\n",
              "      <td>Jan 5, 2015</td>\n",
              "      <td>1.420445e+09</td>\n",
              "      <td>Does it fit Nook GlowLight?</td>\n",
              "      <td>N</td>\n",
              "      <td>No. The nook color or color tablet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>open-ended</td>\n",
              "      <td>0594033926</td>\n",
              "      <td>2 days ago</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Would it fit Nook 1st Edition? 4.9in x 7.7in ?</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I don't think so. The nook color is 5 x 8 so n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>yes/no</td>\n",
              "      <td>0594033926</td>\n",
              "      <td>17 days ago</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Will this fit a Nook Color that's 5 x 8?</td>\n",
              "      <td>Y</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>yes/no</td>\n",
              "      <td>0594033926</td>\n",
              "      <td>Feb 10, 2015</td>\n",
              "      <td>1.423555e+09</td>\n",
              "      <td>will this fit the Samsung Galaxy Tab 4 Nook 10.1</td>\n",
              "      <td>N</td>\n",
              "      <td>No, the tab is smaller than the 'color'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>yes/no</td>\n",
              "      <td>0594033926</td>\n",
              "      <td>Jan 30, 2015</td>\n",
              "      <td>1.422605e+09</td>\n",
              "      <td>does it have a flip stand?</td>\n",
              "      <td>N</td>\n",
              "      <td>No, there is not a flip stand. It has a pocket...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>yes/no</td>\n",
              "      <td>0594033926</td>\n",
              "      <td>Jan 30, 2015</td>\n",
              "      <td>1.422605e+09</td>\n",
              "      <td>does this have a flip stand</td>\n",
              "      <td>?</td>\n",
              "      <td>Hi, no it doesn't</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>open-ended</td>\n",
              "      <td>0594033926</td>\n",
              "      <td>Dec 22, 2014</td>\n",
              "      <td>1.419235e+09</td>\n",
              "      <td>also fits the HD+?</td>\n",
              "      <td>NaN</td>\n",
              "      <td>It should. They are the same size and the char...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>yes/no</td>\n",
              "      <td>0594033926</td>\n",
              "      <td>Nov 16, 2014</td>\n",
              "      <td>1.416125e+09</td>\n",
              "      <td>Does it have 2 positions for the reader? Horiz...</td>\n",
              "      <td>Y</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>open-ended</td>\n",
              "      <td>0594033926</td>\n",
              "      <td>Aug 7, 2014</td>\n",
              "      <td>1.407395e+09</td>\n",
              "      <td>Is there a closure mechanism? Bands, magnetic,...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No- it is more like a normal book would be. It...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  questionType        asin    answerTime      unixTime  \\\n",
              "0       yes/no  0594033926  Dec 27, 2013  1.388131e+09   \n",
              "1       yes/no  0594033926   Jan 5, 2015  1.420445e+09   \n",
              "2   open-ended  0594033926    2 days ago           NaN   \n",
              "3       yes/no  0594033926   17 days ago           NaN   \n",
              "4       yes/no  0594033926  Feb 10, 2015  1.423555e+09   \n",
              "5       yes/no  0594033926  Jan 30, 2015  1.422605e+09   \n",
              "6       yes/no  0594033926  Jan 30, 2015  1.422605e+09   \n",
              "7   open-ended  0594033926  Dec 22, 2014  1.419235e+09   \n",
              "8       yes/no  0594033926  Nov 16, 2014  1.416125e+09   \n",
              "9   open-ended  0594033926   Aug 7, 2014  1.407395e+09   \n",
              "\n",
              "                                            question answerType  \\\n",
              "0  Is this cover the one that fits the old nook c...          Y   \n",
              "1                        Does it fit Nook GlowLight?          N   \n",
              "2     Would it fit Nook 1st Edition? 4.9in x 7.7in ?        NaN   \n",
              "3           Will this fit a Nook Color that's 5 x 8?          Y   \n",
              "4   will this fit the Samsung Galaxy Tab 4 Nook 10.1          N   \n",
              "5                         does it have a flip stand?          N   \n",
              "6                        does this have a flip stand          ?   \n",
              "7                                 also fits the HD+?        NaN   \n",
              "8  Does it have 2 positions for the reader? Horiz...          Y   \n",
              "9  Is there a closure mechanism? Bands, magnetic,...        NaN   \n",
              "\n",
              "                                              answer  \n",
              "0  Yes this fits both the nook color and the same...  \n",
              "1                 No. The nook color or color tablet  \n",
              "2  I don't think so. The nook color is 5 x 8 so n...  \n",
              "3                                                yes  \n",
              "4            No, the tab is smaller than the 'color'  \n",
              "5  No, there is not a flip stand. It has a pocket...  \n",
              "6                                  Hi, no it doesn't  \n",
              "7  It should. They are the same size and the char...  \n",
              "8                                                Yes  \n",
              "9  No- it is more like a normal book would be. It...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "q-jR5R19nIxn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "null_id = []\n",
        "for i, val in enumerate(df['question']):\n",
        "    if len(val) <= 10:\n",
        "        null_id.append(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zT9oZqOnIxs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df =  df.drop(df.index[null_id])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Lka5D8bLnIxw",
        "colab_type": "code",
        "colab": {},
        "outputId": "1427b63f-fe4a-49a0-eea9-f6c299c35228"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 312129 entries, 0 to 314262\n",
            "Data columns (total 7 columns):\n",
            "questionType    312129 non-null object\n",
            "asin            312129 non-null object\n",
            "answerTime      312129 non-null object\n",
            "unixTime        302749 non-null float64\n",
            "question        312129 non-null object\n",
            "answerType      165529 non-null object\n",
            "answer          312129 non-null object\n",
            "dtypes: float64(1), object(6)\n",
            "memory usage: 19.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHpheonxnIx1",
        "colab_type": "code",
        "colab": {},
        "outputId": "cf0ea29c-56a5-461b-f9da-3748a46f7b86"
      },
      "source": [
        "df['asin'].nunique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39371"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VLaoROvnIx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1 = df.drop(['questionType','asin','answerTime','unixTime','answerType'], axis =1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "TrdTQn2pnIx6",
        "colab_type": "code",
        "colab": {},
        "outputId": "369e18f3-3ed6-424c-cdab-9da3add6dc90"
      },
      "source": [
        "df1.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Is this cover the one that fits the old nook c...</td>\n",
              "      <td>Yes this fits both the nook color and the same...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Does it fit Nook GlowLight?</td>\n",
              "      <td>No. The nook color or color tablet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Would it fit Nook 1st Edition? 4.9in x 7.7in ?</td>\n",
              "      <td>I don't think so. The nook color is 5 x 8 so n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Will this fit a Nook Color that's 5 x 8?</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>will this fit the Samsung Galaxy Tab 4 Nook 10.1</td>\n",
              "      <td>No, the tab is smaller than the 'color'</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  \\\n",
              "0  Is this cover the one that fits the old nook c...   \n",
              "1                        Does it fit Nook GlowLight?   \n",
              "2     Would it fit Nook 1st Edition? 4.9in x 7.7in ?   \n",
              "3           Will this fit a Nook Color that's 5 x 8?   \n",
              "4   will this fit the Samsung Galaxy Tab 4 Nook 10.1   \n",
              "\n",
              "                                              answer  \n",
              "0  Yes this fits both the nook color and the same...  \n",
              "1                 No. The nook color or color tablet  \n",
              "2  I don't think so. The nook color is 5 x 8 so n...  \n",
              "3                                                yes  \n",
              "4            No, the tab is smaller than the 'color'  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaSs_jPwnIx9",
        "colab_type": "text"
      },
      "source": [
        "#### Convert text to lowercase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KA-Nxz5onIx-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2 = df1.apply(lambda x: x.astype(str).str.lower())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FU8NJhggnIyA",
        "colab_type": "code",
        "colab": {},
        "outputId": "20957be0-b3c5-4ac6-a4db-92a9e2cdccf4"
      },
      "source": [
        "df2.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>is this cover the one that fits the old nook c...</td>\n",
              "      <td>yes this fits both the nook color and the same...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>does it fit nook glowlight?</td>\n",
              "      <td>no. the nook color or color tablet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>would it fit nook 1st edition? 4.9in x 7.7in ?</td>\n",
              "      <td>i don't think so. the nook color is 5 x 8 so n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>will this fit a nook color that's 5 x 8?</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>will this fit the samsung galaxy tab 4 nook 10.1</td>\n",
              "      <td>no, the tab is smaller than the 'color'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>does it have a flip stand?</td>\n",
              "      <td>no, there is not a flip stand. it has a pocket...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>does this have a flip stand</td>\n",
              "      <td>hi, no it doesn't</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>also fits the hd+?</td>\n",
              "      <td>it should. they are the same size and the char...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>does it have 2 positions for the reader? horiz...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>is there a closure mechanism? bands, magnetic,...</td>\n",
              "      <td>no- it is more like a normal book would be. it...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  \\\n",
              "0  is this cover the one that fits the old nook c...   \n",
              "1                        does it fit nook glowlight?   \n",
              "2     would it fit nook 1st edition? 4.9in x 7.7in ?   \n",
              "3           will this fit a nook color that's 5 x 8?   \n",
              "4   will this fit the samsung galaxy tab 4 nook 10.1   \n",
              "5                         does it have a flip stand?   \n",
              "6                        does this have a flip stand   \n",
              "7                                 also fits the hd+?   \n",
              "8  does it have 2 positions for the reader? horiz...   \n",
              "9  is there a closure mechanism? bands, magnetic,...   \n",
              "\n",
              "                                              answer  \n",
              "0  yes this fits both the nook color and the same...  \n",
              "1                 no. the nook color or color tablet  \n",
              "2  i don't think so. the nook color is 5 x 8 so n...  \n",
              "3                                                yes  \n",
              "4            no, the tab is smaller than the 'color'  \n",
              "5  no, there is not a flip stand. it has a pocket...  \n",
              "6                                  hi, no it doesn't  \n",
              "7  it should. they are the same size and the char...  \n",
              "8                                                yes  \n",
              "9  no- it is more like a normal book would be. it...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAFUXJUwnIyD",
        "colab_type": "code",
        "colab": {},
        "outputId": "8af12a45-95eb-4eac-9152-1584f20c0a3f"
      },
      "source": [
        "questions =  df2['question'].values.tolist()\n",
        "questions = questions[0:len(questions)//312]\n",
        "print(len(questions))\n",
        "questions[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['is this cover the one that fits the old nook color? which i believe is 8x5.',\n",
              " 'does it fit nook glowlight?',\n",
              " 'would it fit nook 1st edition? 4.9in x 7.7in ?',\n",
              " \"will this fit a nook color that's 5 x 8?\",\n",
              " 'will this fit the samsung galaxy tab 4 nook 10.1',\n",
              " 'does it have a flip stand?',\n",
              " 'does this have a flip stand',\n",
              " 'also fits the hd+?',\n",
              " 'does it have 2 positions for the reader? horizontal/vertical thank you kwod',\n",
              " 'is there a closure mechanism? bands, magnetic, etc.?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_r7bzAUUnIyG",
        "colab_type": "code",
        "colab": {},
        "outputId": "cfe5bee3-5dcb-46b7-c348-f456f6ad4059"
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3121"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbsv1OHmnIyI",
        "colab_type": "code",
        "colab": {},
        "outputId": "a3b68f48-2d28-45e9-c8be-84183ea0927c"
      },
      "source": [
        "answers = df2['answer'].values.tolist()\n",
        "answers = answers[0:len(answers)//312]\n",
        "print(len(answers))\n",
        "answers[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['yes this fits both the nook color and the same-shaped nook tablet',\n",
              " 'no. the nook color or color tablet',\n",
              " \"i don't think so. the nook color is 5 x 8 so not sure anything smaller would stay locked in, but would be close.\",\n",
              " 'yes',\n",
              " \"no, the tab is smaller than the 'color'\",\n",
              " 'no, there is not a flip stand. it has a pocket in the front flap. it is a very nice cover.',\n",
              " \"hi, no it doesn't\",\n",
              " 'it should. they are the same size and the charging port is in the same place.',\n",
              " 'yes',\n",
              " \"no- it is more like a normal book would be. it doesn't flop open- so it has never wen an issue for me. the nook clips into a secure and safe holder inside that is small and convenient. this is the best cover i've ever had for my nook- trim and functional (no magnets or elastic needed).\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPS63RkGnIyL",
        "colab_type": "code",
        "colab": {},
        "outputId": "83e16f97-d078-43a1-8791-383f1e7f626e"
      },
      "source": [
        "answers_with_tags = list()\n",
        "for i in range( len( answers ) ):\n",
        "    if type( answers[i] ) == str:\n",
        "        answers_with_tags.append( answers[i] )\n",
        "    else:\n",
        "        questions.pop( i )\n",
        "\n",
        "answers = list()\n",
        "for i in range( len( answers_with_tags ) ) :\n",
        "    answers.append( '<START> ' + answers_with_tags[i] + ' <END>' )\n",
        "\n",
        "tokenizer = preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts( questions + answers )\n",
        "VOCAB_SIZE = len( tokenizer.word_index )+1\n",
        "print( 'VOCAB SIZE : {}'.format( VOCAB_SIZE ))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VOCAB SIZE : 5154\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHIO19B1nIyN",
        "colab_type": "code",
        "colab": {},
        "outputId": "81ffbbe6-4ff6-4079-e8ec-1cb189686460"
      },
      "source": [
        "# encoder_input_data\n",
        "tokenized_questions = tokenizer.texts_to_sequences( questions )\n",
        "maxlen_questions = max( [ len(x) for x in tokenized_questions ] )\n",
        "padded_questions = preprocessing.sequence.pad_sequences( tokenized_questions , maxlen=maxlen_questions , padding='post' )\n",
        "encoder_input_data = np.array( padded_questions )\n",
        "print( encoder_input_data.shape , maxlen_questions )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 52) 52\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoJw2bp5nIyQ",
        "colab_type": "code",
        "colab": {},
        "outputId": "d4b902c0-4f2f-4409-8afe-d18a99fd8048"
      },
      "source": [
        "# decoder_input_data\n",
        "tokenized_answers = tokenizer.texts_to_sequences( answers )\n",
        "maxlen_answers = max( [ len(x) for x in tokenized_answers ] )\n",
        "padded_answers = preprocessing.sequence.pad_sequences( tokenized_answers , maxlen=maxlen_answers , padding='post' )\n",
        "decoder_input_data = np.array( padded_answers )\n",
        "print( decoder_input_data.shape , maxlen_answers )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 612) 612\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbBh5khHnIyT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# decoder_output_data -1 \n",
        "tokenized_answers = tokenizer.texts_to_sequences( answers )\n",
        "for i in range(len(tokenized_answers)) :\n",
        "    tokenized_answers[i] = tokenized_answers[i][1:]\n",
        "padded_answers = preprocessing.sequence.pad_sequences( tokenized_answers , maxlen=maxlen_answers , padding='post' )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcfxWmcHnIyV",
        "colab_type": "code",
        "colab": {},
        "outputId": "03c87240-1304-485c-ba6d-5441c2aba204"
      },
      "source": [
        "padded_answers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 33,  10, 436, ...,   0,   0,   0],\n",
              "       [ 36,   1,  48, ...,   0,   0,   0],\n",
              "       [  5,  58, 169, ...,   0,   0,   0],\n",
              "       ...,\n",
              "       [  1, 281,  43, ...,   0,   0,   0],\n",
              "       [  5,  58, 169, ...,   0,   0,   0],\n",
              "       [ 33,   3, 186, ...,   0,   0,   0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qK1lWMZsnIyY",
        "colab_type": "code",
        "colab": {},
        "outputId": "c120e348-6643-41db-e1b1-0493719e6b68"
      },
      "source": [
        "# # decoder_output_data -2\n",
        "\n",
        "onehot_answers = utils.to_categorical( padded_answers , VOCAB_SIZE )\n",
        "# onehot_answers = sparse_categorical_crossentropy( padded_answers , VOCAB_SIZE )\n",
        "decoder_output_data = np.array( onehot_answers )\n",
        "print( decoder_output_data.shape )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 612, 5154)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9c9tcdwnIyb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Saving all the arrays to storage\n",
        "np.save( 'encoder_input_data.npy' , encoder_input_data )\n",
        "np.save( 'decoder_input_data.npy' , decoder_input_data )\n",
        "np.save( 'decoder_output_data.npy' , decoder_output_data )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ceu13b16nIyf",
        "colab_type": "text"
      },
      "source": [
        "### Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmOXSbRhnIyg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_inputs = tf.keras.layers.Input(shape=( None , ))\n",
        "encoder_embedding = tf.keras.layers.Embedding( VOCAB_SIZE, 200 , mask_zero=True ) (encoder_inputs)\n",
        "encoder_outputs , state_h , state_c = tf.keras.layers.LSTM( 200 , return_state=True )( encoder_embedding )\n",
        "encoder_states = [ state_h , state_c ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hn-CvFa_nIyk",
        "colab_type": "code",
        "colab": {},
        "outputId": "909a9f0e-c408-4c35-ef78-8443ea61eb15"
      },
      "source": [
        "decoder_inputs = tf.keras.layers.Input(shape=( None ,  ))\n",
        "decoder_embedding = tf.keras.layers.Embedding( VOCAB_SIZE, 200 , mask_zero=True) (decoder_inputs)\n",
        "decoder_lstm = tf.keras.layers.LSTM( 200 , return_state=True , return_sequences=True )\n",
        "decoder_outputs , _ , _ = decoder_lstm ( decoder_embedding , initial_state=encoder_states )\n",
        "decoder_dense = tf.keras.layers.Dense( VOCAB_SIZE , activation=tf.keras.activations.softmax ) \n",
        "output = decoder_dense ( decoder_outputs )\n",
        "\n",
        "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], output )\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='categorical_crossentropy')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 200)    1030800     input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, None, 200)    1030800     input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 200), (None, 320800      embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 200),  320800      embedding_3[0][0]                \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 5154)   1035954     lstm_3[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 3,739,154\n",
            "Trainable params: 3,739,154\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6JSVIAJnIym",
        "colab_type": "code",
        "colab": {},
        "outputId": "72482ee5-cd6c-470d-937a-06d4b0661034"
      },
      "source": [
        "model.fit([encoder_input_data , decoder_input_data], decoder_output_data, batch_size=10, epochs=50, use_multiprocessing= True) \n",
        "# model.save( 'model.h5' )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1000 samples\n",
            "Epoch 1/50\n",
            "1000/1000 [==============================] - 247s 247ms/sample - loss: 0.4015\n",
            "Epoch 2/50\n",
            "1000/1000 [==============================] - 201s 201ms/sample - loss: 0.3826\n",
            "Epoch 3/50\n",
            "1000/1000 [==============================] - 163s 163ms/sample - loss: 0.3738\n",
            "Epoch 4/50\n",
            "1000/1000 [==============================] - 154s 154ms/sample - loss: 0.3600\n",
            "Epoch 5/50\n",
            "1000/1000 [==============================] - 145s 145ms/sample - loss: 0.3502\n",
            "Epoch 6/50\n",
            "1000/1000 [==============================] - 144s 144ms/sample - loss: 0.3418\n",
            "Epoch 7/50\n",
            "1000/1000 [==============================] - 145s 145ms/sample - loss: 0.3344\n",
            "Epoch 8/50\n",
            "1000/1000 [==============================] - 144s 144ms/sample - loss: 0.3275\n",
            "Epoch 9/50\n",
            "1000/1000 [==============================] - 145s 145ms/sample - loss: 0.3212\n",
            "Epoch 10/50\n",
            "1000/1000 [==============================] - 147s 147ms/sample - loss: 0.3151\n",
            "Epoch 11/50\n",
            "1000/1000 [==============================] - 147s 147ms/sample - loss: 0.3095\n",
            "Epoch 12/50\n",
            "1000/1000 [==============================] - 145s 145ms/sample - loss: 0.3029\n",
            "Epoch 13/50\n",
            "1000/1000 [==============================] - 146s 146ms/sample - loss: 0.2977\n",
            "Epoch 14/50\n",
            "1000/1000 [==============================] - 145s 145ms/sample - loss: 0.2919\n",
            "Epoch 15/50\n",
            "1000/1000 [==============================] - 145s 145ms/sample - loss: 0.2864\n",
            "Epoch 16/50\n",
            "1000/1000 [==============================] - 146s 146ms/sample - loss: 0.2812\n",
            "Epoch 17/50\n",
            "1000/1000 [==============================] - 149s 149ms/sample - loss: 0.2759\n",
            "Epoch 18/50\n",
            "1000/1000 [==============================] - 146s 146ms/sample - loss: 0.2701\n",
            "Epoch 19/50\n",
            "1000/1000 [==============================] - 145s 145ms/sample - loss: 0.2648\n",
            "Epoch 20/50\n",
            "1000/1000 [==============================] - 157s 157ms/sample - loss: 0.2602\n",
            "Epoch 21/50\n",
            "1000/1000 [==============================] - 151s 151ms/sample - loss: 0.2546\n",
            "Epoch 22/50\n",
            "1000/1000 [==============================] - 152s 152ms/sample - loss: 0.2499\n",
            "Epoch 23/50\n",
            "1000/1000 [==============================] - 151s 151ms/sample - loss: 0.2454\n",
            "Epoch 24/50\n",
            "1000/1000 [==============================] - 155s 155ms/sample - loss: 0.2402\n",
            "Epoch 25/50\n",
            "1000/1000 [==============================] - 151s 151ms/sample - loss: 0.2354\n",
            "Epoch 26/50\n",
            "1000/1000 [==============================] - 149s 149ms/sample - loss: 0.2305\n",
            "Epoch 27/50\n",
            "1000/1000 [==============================] - 148s 148ms/sample - loss: 0.2255\n",
            "Epoch 28/50\n",
            "1000/1000 [==============================] - 146s 146ms/sample - loss: 0.2205\n",
            "Epoch 29/50\n",
            "1000/1000 [==============================] - 152s 152ms/sample - loss: 0.2164\n",
            "Epoch 30/50\n",
            "1000/1000 [==============================] - 146s 146ms/sample - loss: 0.2114\n",
            "Epoch 31/50\n",
            "1000/1000 [==============================] - 147s 147ms/sample - loss: 0.2068\n",
            "Epoch 32/50\n",
            "1000/1000 [==============================] - 153s 153ms/sample - loss: 0.2019\n",
            "Epoch 33/50\n",
            "1000/1000 [==============================] - 147s 147ms/sample - loss: 0.1975\n",
            "Epoch 34/50\n",
            "1000/1000 [==============================] - 149s 149ms/sample - loss: 0.1930\n",
            "Epoch 35/50\n",
            "1000/1000 [==============================] - 154s 154ms/sample - loss: 0.1888\n",
            "Epoch 36/50\n",
            "1000/1000 [==============================] - 146s 146ms/sample - loss: 0.1846\n",
            "Epoch 37/50\n",
            "1000/1000 [==============================] - 143s 143ms/sample - loss: 0.1802\n",
            "Epoch 38/50\n",
            "1000/1000 [==============================] - 144s 144ms/sample - loss: 0.1757\n",
            "Epoch 39/50\n",
            "1000/1000 [==============================] - 143s 143ms/sample - loss: 0.1711\n",
            "Epoch 40/50\n",
            "1000/1000 [==============================] - 144s 144ms/sample - loss: 0.1671\n",
            "Epoch 41/50\n",
            "1000/1000 [==============================] - 147s 147ms/sample - loss: 0.1629\n",
            "Epoch 42/50\n",
            "1000/1000 [==============================] - 145s 145ms/sample - loss: 0.1593\n",
            "Epoch 43/50\n",
            "1000/1000 [==============================] - 144s 144ms/sample - loss: 0.1548\n",
            "Epoch 44/50\n",
            "1000/1000 [==============================] - 146s 146ms/sample - loss: 0.1503\n",
            "Epoch 45/50\n",
            "1000/1000 [==============================] - 146s 146ms/sample - loss: 0.1472\n",
            "Epoch 46/50\n",
            "1000/1000 [==============================] - 144s 144ms/sample - loss: 0.1429\n",
            "Epoch 47/50\n",
            "1000/1000 [==============================] - 145s 145ms/sample - loss: 0.1393\n",
            "Epoch 48/50\n",
            "1000/1000 [==============================] - 148s 148ms/sample - loss: 0.1348\n",
            "Epoch 49/50\n",
            "1000/1000 [==============================] - 151s 151ms/sample - loss: 0.1320\n",
            "Epoch 50/50\n",
            "1000/1000 [==============================] - 147s 147ms/sample - loss: 0.1282\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x236fb654348>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8ulQS7CnIyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save( 'model_lstm.h5' )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaGalayjnIyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pkl_filename = \"model_lstm_pkl2.pkl\"\n",
        "\n",
        "saved_model = pickle.dumps(pkl_filename) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9YPgxawnIyv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_inference_models():\n",
        "    \n",
        "    encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n",
        "    \n",
        "    decoder_state_input_h = tf.keras.layers.Input(shape=( 200 ,))\n",
        "    decoder_state_input_c = tf.keras.layers.Input(shape=( 200 ,))\n",
        "    \n",
        "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "    \n",
        "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "        decoder_embedding , initial_state=decoder_states_inputs)\n",
        "    decoder_states = [state_h, state_c]\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "    decoder_model = tf.keras.models.Model(\n",
        "        [decoder_inputs] + decoder_states_inputs,\n",
        "        [decoder_outputs] + decoder_states)\n",
        "    \n",
        "    return encoder_model , decoder_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mZvK3uVnIyw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def str_to_tokens( sentence : str ):\n",
        "    words = sentence.lower().split()\n",
        "    tokens_list = list()\n",
        "    for word in words:\n",
        "        tokens_list.append( tokenizer.word_index[ word ] ) \n",
        "    return preprocessing.sequence.pad_sequences( [tokens_list] , maxlen=maxlen_questions , padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKg1mAqHnIyx",
        "colab_type": "code",
        "colab": {},
        "outputId": "a2199ac1-707a-4b20-eecb-aa9fccbbe528"
      },
      "source": [
        "enc_model , dec_model = make_inference_models()\n",
        "\n",
        "for _ in range(10):\n",
        "    states_values = enc_model.predict( str_to_tokens( input( 'Enter question : ' ) ) )\n",
        "    empty_target_seq = np.zeros( ( 1 , 1 ) )\n",
        "    empty_target_seq[0, 0] = tokenizer.word_index['start']\n",
        "    stop_condition = False\n",
        "    decoded_translation = ''\n",
        "    while not stop_condition :\n",
        "        dec_outputs , h , c = dec_model.predict([ empty_target_seq ] + states_values )\n",
        "        sampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n",
        "        sampled_word = None\n",
        "        for word , index in tokenizer.word_index.items() :\n",
        "            if sampled_word_index == index :\n",
        "                decoded_translation += ' {}'.format( word )\n",
        "                sampled_word = word\n",
        "        \n",
        "        if sampled_word == 'end' or len(decoded_translation.split()) > maxlen_answers:\n",
        "            stop_condition = True\n",
        "            \n",
        "        empty_target_seq = np.zeros( ( 1 , 1 ) )  \n",
        "        empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
        "        states_values = [ h , c ] \n",
        "\n",
        "    print( decoded_translation )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter question : will this fit a nook color that's 5 x 8\n",
            " yes end\n",
            "Enter question : how are you\n",
            " this is a standard usb cable for a be version for a usb version jack end\n",
            "Enter question : size\n",
            " hi of the screen states flap compatible with the film i hope this helps end\n",
            "Enter question : does it fit nook glowlight\n",
            " no the nook color or color tablet i have a 2 2 inch and it works great a great charger but you can use it for it for this is the best to have a few 8 end\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}